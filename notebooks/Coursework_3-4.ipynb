{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example two-layer classifier models\n",
    "\n",
    "Below example code is given for creating instances of the CIFAR-10 and CIFAR-100 data provider objects and using them to train simple two-layer feedforward network models with rectified linear activations in TensorFlow. You may wish to use this code as a starting point for your own experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/EJ/miniconda2/envs/mlp/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from mlp.data_providers import CIFAR10DataProvider, CIFAR100DataProvider\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = CIFAR10DataProvider('train', batch_size=50)\n",
    "valid_data = CIFAR10DataProvider('valid', batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_connected_layer(inputs, input_dim, output_dim, nonlinearity=tf.nn.relu, name='fc-layer'):\n",
    "    with tf.name_scope(name):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal([input_dim, output_dim], stddev=2. / (input_dim + output_dim)**0.5), \n",
    "            name='weights'\n",
    "        )\n",
    "        biases = tf.Variable(tf.zeros([output_dim]), name='biases')\n",
    "        outputs = nonlinearity(tf.matmul(inputs, weights) + biases)\n",
    "        return outputs\n",
    "    \n",
    "def err_acc(outputs, targets):\n",
    "    with tf.name_scope('error'):\n",
    "        error = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(outputs, targets))\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(outputs, 1), tf.argmax(targets, 1)), tf.float32))\n",
    "    return error, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_optimizer(optimizer, error, scheduler=False, init_learning_rate=0.01):\n",
    "    func_dict = {\n",
    "        'adam': tf.train.AdamOptimizer,\n",
    "        'gd': tf.train.GradientDescentOptimizer,\n",
    "        'adagrad': tf.train.AdagradOptimizer,\n",
    "        'momentum': tf.train.MomentumOptimizer,\n",
    "        'rms': tf.train.RMSPropOptimizer\n",
    "    }\n",
    "    with tf.name_scope('train'):\n",
    "        train_step = func_dict.get(optimizer, tf.train.AdamOptimizer)\n",
    "\n",
    "        if scheduler:\n",
    "            global_step = tf.Variable(0, trainable=False)\n",
    "            learning_rate = tf.train.exponential_decay(init_learning_rate, global_step, 100000, 0.96, staircase=True)\n",
    "\n",
    "            train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(error, global_step=global_step)\n",
    "        else:\n",
    "            train_step = train_step(init_learning_rate).minimize(error)\n",
    "                \n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def graph_summary(error, accuracy, name, graph):\n",
    "    tf.summary.scalar('error', error)\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    summary_op = tf.summary.merge_all()        \n",
    "\n",
    "    train_writer = tf.summary.FileWriter(os.path.join('tf-log', name, 'train'), graph=graph)\n",
    "    valid_writer = tf.summary.FileWriter(os.path.join('tf-log', name, 'valid'), graph=graph)\n",
    "    return summary_op, train_writer, valid_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model(num_layers=2, num_hidden=200, optimizer='gd', learning_rate=0.01):\n",
    "    inputs = tf.placeholder(tf.float32, [None, train_data.inputs.shape[1]], 'inputs')\n",
    "    targets = tf.placeholder(tf.float32, [None, train_data.num_classes], 'targets')\n",
    "    \n",
    "    lay = dict()\n",
    "    \n",
    "#     with tf.name_scope('fc-layer-1'):\n",
    "#         lay['fc-layer-1'] = fully_connected_layer(inputs, train_data.inputs.shape[1], num_hidden)\n",
    "    \n",
    "#     for layer in range(num_layers):\n",
    "#         with tf.name_scope('fc-layer-{}'.format(layer+2)):\n",
    "#             lay['fc-layer-{}'.format(layer+2)] = fully_connected_layer(lay['fc-layer-{}'.format(layer+1)], num_hidden, num_hidden)\n",
    "        \n",
    "#     with tf.name_scope('output-layer'):\n",
    "#         outputs = fully_connected_layer(lay['fc-layer-{}'.format(num_layers+1)], num_hidden, train_data.num_classes, tf.identity)\n",
    "\n",
    "    with tf.name_scope('fc-layer-1'):\n",
    "        hidden_1 = fully_connected_layer(inputs, train_data.inputs.shape[1], num_hidden)\n",
    "    with tf.name_scope('fc-layer-2'):\n",
    "        hidden_2 = fully_connected_layer(hidden_1, num_hidden, num_hidden)\n",
    "    with tf.name_scope('fc-layer-3'):\n",
    "        hidden_3 = fully_connected_layer(hidden_2, num_hidden, num_hidden)\n",
    "    with tf.name_scope('output-layer'):\n",
    "        outputs = fully_connected_layer(hidden_3, num_hidden, train_data.num_classes, tf.identity)\n",
    "        \n",
    "    with tf.name_scope('error'):\n",
    "        error = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(outputs, targets))\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = tf.reduce_mean(tf.cast(\n",
    "                tf.equal(tf.argmax(outputs, 1), tf.argmax(targets, 1)), \n",
    "                tf.float32))\n",
    "        \n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    starter_learning_rate = learning_rate\n",
    "    learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, 1000, 0.96)\n",
    "\n",
    "    with tf.name_scope('train'):\n",
    "        train_step = get_optimizer(optimizer)(learning_rate).minimize(error, global_step=global_step)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for e in range(20):\n",
    "            running_error = 0.\n",
    "            running_accuracy = 0.\n",
    "\n",
    "            for input_batch, target_batch in train_data:\n",
    "                _, batch_error, batch_acc = sess.run(\n",
    "                    [train_step, error, accuracy], \n",
    "                    feed_dict={inputs: input_batch, targets: target_batch})\n",
    "\n",
    "                running_error += batch_error\n",
    "                running_accuracy += batch_acc\n",
    "\n",
    "            running_error /= train_data.num_batches\n",
    "            running_accuracy /= train_data.num_batches\n",
    "            print('End of epoch {0:02d}: err(train)={1:.2f} acc(train)={2:.2f}'\n",
    "                  .format(e + 1, running_error, running_accuracy))\n",
    "\n",
    "            if (e + 1) % 5 == 0:\n",
    "                valid_error = 0.\n",
    "                valid_accuracy = 0.\n",
    "                for input_batch, target_batch in valid_data:\n",
    "                    batch_error, batch_acc = sess.run(\n",
    "                        [error, accuracy], \n",
    "                        feed_dict={inputs: input_batch, targets: target_batch})\n",
    "                    valid_error += batch_error\n",
    "                    valid_accuracy += batch_acc\n",
    "\n",
    "                valid_error /= valid_data.num_batches\n",
    "                valid_accuracy /= valid_data.num_batches\n",
    "                print('                 err(valid)={0:.2f} acc(valid)={1:.2f}'\n",
    "                       .format(valid_error, valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 01: err(train)=2.01 acc(train)=0.27\n",
      "End of epoch 02: err(train)=1.78 acc(train)=0.36\n",
      "End of epoch 03: err(train)=1.69 acc(train)=0.39\n",
      "End of epoch 04: err(train)=1.63 acc(train)=0.42\n",
      "End of epoch 05: err(train)=1.58 acc(train)=0.43\n",
      "                 err(valid)=1.61 acc(valid)=0.43\n",
      "End of epoch 06: err(train)=1.54 acc(train)=0.45\n",
      "End of epoch 07: err(train)=1.50 acc(train)=0.46\n",
      "End of epoch 08: err(train)=1.47 acc(train)=0.47\n",
      "End of epoch 09: err(train)=1.44 acc(train)=0.48\n",
      "End of epoch 10: err(train)=1.41 acc(train)=0.49\n",
      "                 err(valid)=1.53 acc(valid)=0.47\n",
      "End of epoch 11: err(train)=1.39 acc(train)=0.50\n",
      "End of epoch 12: err(train)=1.37 acc(train)=0.51\n",
      "End of epoch 13: err(train)=1.35 acc(train)=0.52\n",
      "End of epoch 14: err(train)=1.32 acc(train)=0.53\n",
      "End of epoch 15: err(train)=1.30 acc(train)=0.53\n",
      "                 err(valid)=1.49 acc(valid)=0.48\n",
      "End of epoch 16: err(train)=1.28 acc(train)=0.54\n",
      "End of epoch 17: err(train)=1.25 acc(train)=0.55\n",
      "End of epoch 18: err(train)=1.23 acc(train)=0.55\n",
      "End of epoch 19: err(train)=1.21 acc(train)=0.56\n",
      "End of epoch 20: err(train)=1.19 acc(train)=0.57\n",
      "                 err(valid)=1.47 acc(valid)=0.49\n"
     ]
    }
   ],
   "source": [
    "build_model(optimizer='gd', learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 01: err(train)=2.26 acc(train)=0.14\n",
      "End of epoch 02: err(train)=1.99 acc(train)=0.26\n",
      "End of epoch 03: err(train)=1.84 acc(train)=0.33\n",
      "End of epoch 04: err(train)=1.77 acc(train)=0.37\n",
      "End of epoch 05: err(train)=1.71 acc(train)=0.39\n",
      "                 err(valid)=1.75 acc(valid)=0.39\n",
      "End of epoch 06: err(train)=1.66 acc(train)=0.40\n",
      "End of epoch 07: err(train)=1.62 acc(train)=0.42\n",
      "End of epoch 08: err(train)=1.59 acc(train)=0.43\n",
      "End of epoch 09: err(train)=1.56 acc(train)=0.44\n",
      "End of epoch 10: err(train)=1.53 acc(train)=0.45\n",
      "                 err(valid)=1.59 acc(valid)=0.43\n",
      "End of epoch 11: err(train)=1.51 acc(train)=0.46\n",
      "End of epoch 12: err(train)=1.49 acc(train)=0.46\n",
      "End of epoch 13: err(train)=1.47 acc(train)=0.47\n",
      "End of epoch 14: err(train)=1.46 acc(train)=0.48\n",
      "End of epoch 15: err(train)=1.44 acc(train)=0.48\n",
      "                 err(valid)=1.55 acc(valid)=0.45\n",
      "End of epoch 16: err(train)=1.43 acc(train)=0.49\n",
      "End of epoch 17: err(train)=1.41 acc(train)=0.50\n",
      "End of epoch 18: err(train)=1.40 acc(train)=0.50\n",
      "End of epoch 19: err(train)=1.38 acc(train)=0.50\n",
      "End of epoch 20: err(train)=1.37 acc(train)=0.51\n",
      "                 err(valid)=1.49 acc(valid)=0.47\n"
     ]
    }
   ],
   "source": [
    "build_model(4, optimizer='gd', learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.float32, [None, train_data.inputs.shape[1]], 'inputs')\n",
    "targets = tf.placeholder(tf.float32, [None, train_data.num_classes], 'targets')\n",
    "num_hidden = 200\n",
    "\n",
    "with tf.name_scope('fc-layer-1'):\n",
    "    hidden_1 = fully_connected_layer(inputs, train_data.inputs.shape[1], num_hidden)\n",
    "with tf.name_scope('fc-layer-2'):\n",
    "    hidden_2 = fully_connected_layer(hidden_1, num_hidden, num_hidden)\n",
    "with tf.name_scope('output-layer'):\n",
    "    outputs = fully_connected_layer(hidden_2, num_hidden, train_data.num_classes, tf.identity)\n",
    "\n",
    "with tf.name_scope('error'):\n",
    "    error = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(outputs, targets))\n",
    "with tf.name_scope('accuracy'):\n",
    "    accuracy = tf.reduce_mean(tf.cast(\n",
    "            tf.equal(tf.argmax(outputs, 1), tf.argmax(targets, 1)), \n",
    "            tf.float32))\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.AdamOptimizer().minimize(error)\n",
    "    \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_sess(init):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for e in range(100):\n",
    "            running_error = 0.\n",
    "            running_accuracy = 0.\n",
    "\n",
    "            for input_batch, target_batch in train_data:\n",
    "                _, batch_error, batch_acc = sess.run(\n",
    "                    [train_step, error, accuracy], \n",
    "                    feed_dict={inputs: input_batch, targets: target_batch})\n",
    "\n",
    "                running_error += batch_error\n",
    "                running_accuracy += batch_acc\n",
    "\n",
    "            running_error /= train_data.num_batches\n",
    "            running_accuracy /= train_data.num_batches\n",
    "            print('End of epoch {0:02d}: err(train)={1:.2f} acc(train)={2:.2f}'\n",
    "                  .format(e + 1, running_error, running_accuracy))\n",
    "\n",
    "            if (e + 1) % 5 == 0:\n",
    "                valid_error = 0.\n",
    "                valid_accuracy = 0.\n",
    "                for input_batch, target_batch in valid_data:\n",
    "                    batch_error, batch_acc = sess.run(\n",
    "                        [error, accuracy], \n",
    "                        feed_dict={inputs: input_batch, targets: target_batch})\n",
    "                    valid_error += batch_error\n",
    "                    valid_accuracy += batch_acc\n",
    "\n",
    "                valid_error /= valid_data.num_batches\n",
    "                valid_accuracy /= valid_data.num_batches\n",
    "                print('                 err(valid)={0:.2f} acc(valid)={1:.2f}'\n",
    "                       .format(valid_error, valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_sess(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def build_graph(name='graph', num_layers=2, num_hidden=200, scheduler=False, learning_rate=0.01, activation=tf.nn.relu):\n",
    "    graph = tf.Graph()\n",
    "    \n",
    "    with graph.as_default():\n",
    "        inputs = tf.placeholder(tf.float32, [None, train_data.inputs.shape[1]], 'inputs')\n",
    "        targets = tf.placeholder(tf.float32, [None, train_data.num_classes], 'targets')\n",
    "        \n",
    "        lay = dict()\n",
    "    \n",
    "        lay['fc-layer-1'] = fully_connected_layer(inputs, train_data.inputs.shape[1], num_hidden, activation, 'fc-layer-1')\n",
    "        \n",
    "        for layer in range(num_layers):\n",
    "            lay['fc-layer-{}'.format(layer+2)] = fully_connected_layer(\n",
    "                lay['fc-layer-{}'.format(layer+1)],\n",
    "                num_hidden, num_hidden,\n",
    "                activation,\n",
    "                'fc-layer-{}'.format(layer+2)\n",
    "            )\n",
    "\n",
    "        outputs = fully_connected_layer(\n",
    "            lay['fc-layer-{}'.format(num_layers+1)],\n",
    "            num_hidden, train_data.num_classes,\n",
    "            tf.identity,\n",
    "            'output-layer'\n",
    "        )\n",
    "\n",
    "#         hidden_1 = fully_connected_layer(inputs, train_data.inputs.shape[1], num_hidden, activation, 'fc-layer-1')\n",
    "#         hidden_2 = fully_connected_layer(hidden_1, num_hidden, num_hidden, activation, 'fc-layer-2')\n",
    "#         outputs = fully_connected_layer(hidden_2, num_hidden, train_data.num_classes, tf.identity, 'output-layer')\n",
    "\n",
    "        error, accuracy = err_acc(outputs, targets)\n",
    "\n",
    "        train_step = get_optimizer('adam', error, scheduler, learning_rate)\n",
    "    \n",
    "#         with tf.name_scope('train'):\n",
    "#             train_step = tf.train.AdamOptimizer().minimize(error)\n",
    "            \n",
    "        summary_op, train_writer, valid_writer = graph_summary(error, accuracy, name, graph)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "    sess = tf.InteractiveSession(graph=graph)\n",
    "    num_epoch = 40\n",
    "    valid_inputs = valid_data.inputs\n",
    "    valid_targets = valid_data.to_one_of_k(valid_data.targets)\n",
    "    sess.run(init)\n",
    "    for e in range(num_epoch):\n",
    "#         print('Epoch {}'.format(e))\n",
    "        for b, (input_batch, target_batch) in enumerate(train_data):\n",
    "            _, summary = sess.run(\n",
    "                [train_step, summary_op],\n",
    "                feed_dict={inputs: input_batch, targets: target_batch})\n",
    "            train_writer.add_summary(summary, e * train_data.num_batches + b)\n",
    "            if b % 100 == 0:\n",
    "                valid_summary = sess.run(\n",
    "                    summary_op, feed_dict={inputs: valid_inputs, targets: valid_targets})\n",
    "                valid_writer.add_summary(valid_summary, e * train_data.num_batches + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "build_graph(name='test/graph4', num_layers=5, num_hidden=100, scheduler=False, learning_rate=0.1, activation=tf.nn.elu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 1\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 2\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 3\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 4\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 5\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 6\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 7\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 8\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 9\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 10\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 11\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 12\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 13\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 14\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 15\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 16\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 17\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 18\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 19\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 20\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 21\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 22\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 23\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 24\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 25\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 26\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 27\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 28\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 29\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 30\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 31\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 32\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 33\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 34\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 35\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 36\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 37\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 38\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "Epoch 39\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "build_graph('ac/tanh', tf.tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n"
     ]
    }
   ],
   "source": [
    "build_graph('ac/elu', tf.nn.elu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n"
     ]
    }
   ],
   "source": [
    "build_graph('ac/sigmoid', tf.sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n"
     ]
    }
   ],
   "source": [
    "build_graph(\n",
    "    name='layers/lay=2,hidden=50',\n",
    "    num_layers=2,\n",
    "    num_hidden=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n"
     ]
    }
   ],
   "source": [
    "build_graph(\n",
    "    name='layers/lay=2,hidden=100',\n",
    "    num_layers=2,\n",
    "    num_hidden=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n"
     ]
    }
   ],
   "source": [
    "build_graph(\n",
    "    name='layers/lay=2,hidden=200',\n",
    "    num_layers=2,\n",
    "    num_hidden=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n"
     ]
    }
   ],
   "source": [
    "build_graph(\n",
    "    name='layers/lay=2,hidden=400',\n",
    "    num_layers=2,\n",
    "    num_hidden=400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n"
     ]
    }
   ],
   "source": [
    "build_graph(\n",
    "    name='layers/lay=1,hidden=100',\n",
    "    num_layers=1,\n",
    "    num_hidden=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "depths = [1, 2, 4, 5]\n",
    "widths = [50, 100, 200, 400]\n",
    "for depth in depths:\n",
    "    for width in widths:\n",
    "        build_graph(\n",
    "            name='layer/dep={},wid={}'.format(depth, width),\n",
    "            num_layers=depth,\n",
    "            num_hidden=width\n",
    "        )\n",
    "        print('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add scheduler\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n"
     ]
    }
   ],
   "source": [
    "build_graph(\n",
    "    name='schedules/test5',\n",
    "    num_layers=2,\n",
    "    num_hidden=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rates = [0.1]\n",
    "for lr in learning_rates:\n",
    "    build_graph(\n",
    "        name='schedules/lr={}'.format(lr),\n",
    "        num_hidden=100,\n",
    "        scheduler=True,\n",
    "        learning_rate=lr\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mlp]",
   "language": "python",
   "name": "conda-env-mlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
